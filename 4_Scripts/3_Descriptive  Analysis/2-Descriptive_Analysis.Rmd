---
title: "Suite de l'analyse descriptive du jeu de données SIWIM"
output: 
  html_document:
    df_print: paged
---

```{r "setup", include=FALSE}
# Configuration locale du chemin du projet SIWIM :
knitr::opts_knit$set(root.dir = normalizePath("Z:/Data Science/R/SiWIM-project")) 
```

# Introduction

Nous poursuivons dans cette section notre analyse descriptive du jeu de données par une étude bi-dimensionnelle des variables qualitatives et quantitatives. 

Nous compléterons avec quelques indicateurs quantitatifs et graphiques.

Enfin, nous utiliserons des techniques d'analyses multidimensionnelles : les analyses factorielles et le clustering non supervisé afin de poursuivre l'exploration de notre jeu de données.


```{r}
# chargement des librairies 

library(data.table)
library(questionr)  # calcul Vcramer et des fréquences
library(ggplot2)
library(corrplot)   # affichage matrice des correlations
library(FactoMineR) # analyses factorielles
library(factoextra) # beaux graphiques pour analyses factorielles et clustering
library(fastcluster) # clustering CAH rapide
library(cluster)     # clustering CLARA

```

Nous choisissons de poursuivre nos analyses sur la base du jeu de données dont les données manquantes ont été imputées :

```{r}

# Chargement
siwim_imputed <- read.csv("2_Data/2_Retraitees/SiWIM_data_after_input.csv")
#siwim_imputed <- read.csv("2_Data/2_Retraitees/SiWIM_data_missing_deleted.csv")

# Structure du fichier
str(siwim_imputed)

# Transformation en data table
setDT(siwim_imputed)

```

On effectue quelques conversions post import des données :
```{r}

# Conversion en factor de Subclass_ID
siwim_imputed[, Subclass_ID := factor(as.character(Subclass_ID))]

# Conversion en factor de la variable Axle_groups
siwim_imputed[, Axle_groups := factor(as.character(Axle_groups))]

# Conversion en factor de la variable Nb_Axles (nombre d'axes)
siwim_imputed[, Nb_axles := as.factor(as.character(Nb_axles))]

# Conversion en factor de la variable Annee
siwim_imputed[, Annee := factor(as.character(Annee))]

# Conversion en factor de la variable Mois_num
siwim_imputed[, Mois_num := factor(as.character(Mois_num))]

# Conversion en factor de la variable Jour_num
siwim_imputed[, Jour_num := factor(as.character(Jour_num))]

# Conversion en factor de la variable Heure
siwim_imputed[, Heure := factor(Heure)]

# Structure apres conversions
str(siwim_imputed)
```


Nous recréons deux jeux de données séparant variables quantitatives et qualitatives :

```{r}
varquanti <- siwim_imputed[, lapply(siwim_imputed, is.numeric) == TRUE, with = FALSE]
varquali <- siwim_imputed[,lapply(siwim_imputed,is.numeric) == FALSE, with = FALSE]
```

# Retour sur variables quanti (post - imputation)

Nous construisons quelques boxplot, des variables quantitatives les plus intéressantes, après avoir imputer les données.

```{r}
# Nombre d'essieux
ggplot(varquanti,aes("", y = N)) + geom_boxplot()

# Distance totale entre les essieux les plus éloignés
ggplot(varquanti,aes("", y = total_axle_dist)) + geom_boxplot()

# Temperature utilisée par la compensation
ggplot(varquanti,aes("", y = T)) + geom_boxplot()

# Vitesse
ggplot(varquanti,aes("", y = Vitesse)) + geom_boxplot()

# Masse du camion
ggplot(varquanti,aes("", y = MGV)) + geom_boxplot()
```

# Analyse bi dimensionnelle (étude des liaisons)


### Etude des liaisons entre variables qualitatives


```{r}
# Croisement heure  et jour de passage
table(varquali$Jour_semaine,varquali$Heure)
plot(table(varquali$Jour_semaine,varquali$Heure),main = "fréquence de circulation suivant le jour et l'heure")
```

Les camions circulent peu le Samedi et le Dimanche et nettement moins la nuit.

```{r}
# On travaille avec un sous ensemble utiles des variables qualitatives
varquali2 <- varquali[,.(Warning_flags,Subclass_ID,Axle_groups,Mois_annee,Jour_semaine,Heure,Lane,Nb_axles,Anomalie)]
varquali2 <- as.data.frame(varquali2)
```

Nous allons à présent étudier la force de la liaison entre les variables qualitatives, et pour cela, calculer le V de Cramer.
Le V de Cramer présente l'avantage d'offrir une mesure absolue de l'intensité de la liaison entre deux variables qualitatives.
La liaison est nulle quand V =0, liaison est maximales lorsque V = 1.

```{r}
# liaisons entre variables qualitatives (calcul du V de Cramer)
cramer <- matrix(NA, ncol(varquali2), ncol(varquali2))
for (i in (1:ncol(varquali2))){
  for (j in (1:ncol(varquali2))){
    cramer[i,j] <- cramer.v(table(varquali2[,i], varquali2[,j]))
  }
}

colnames(cramer) <- colnames(varquali2)
rownames(cramer) <- colnames(varquali2)

corrplot(cramer, method="number")
```

 Il semble y avoir un lien entre le fait de rouler à gauche ou à droite (`lane`) et le mois de circulation. Attention car les données ont été récupérées sur un nombre de mois limités (ici 5 mois).
Il semble également y avoir un lien entre l'heure de circulation et le fait de rouler à gauche ou à droite. Mais ce lien est plutôt faible.

Le Vcramer est important entre la classification réalisée par le système `SubClasss_ID` et le groupe d'essieux `Axle_Group` ce qui parait logique.
Le nombre d'axes `Nb_Axles` est lié totalement au groupe d'essieux`Axles_groups`. 

Il semble également y avoir un lien entre le déclenchement d'une anomalie `Anomalie` et la classification réalisée par le système : des groupes de camions sont-ils plus sujets à déclencher des anomalies ?

### Etude des liaisons entre variables quantitatives


```{r}
# On travaille avec un sous ensemble utiles des variables quantitatives
varquanti2 <- varquanti[,c("N", "total_axle_dist","T","Reduced_chi_squared","Time_num","Vitesse","MGV")]
```

Nous calculons le coefficient de corrélation linéaire de Pearson entre les variables quantitatives :

```{r}
# Matrice de correlation (Pearson) 
corr <- cor(varquanti2)
corrplot(corr, method="number")
```

La distance totale entre les essieux `total_axle_dist` est corrélée linéairement au nombre d'essieux `N`.
Une corrélation négative est observable, plutot forte, entre vitesse `Vitesse` et masse `Masse` (plus le poids lourd est massique, moins il va vite).
Une corrélation linéaire non négligeable existe également entre le nombre d'essieux et la masse du camion.
Une faible corrélation entre masse et nombre d'essieux et entre vitesse et nombre d'essieux (corrélation négative).

Nous observons ainsi plusieurs relations linéaires entre les données physiques. Ainsi il apparait qu'un camion massique roulera moins vite, qu'il est plus long et a plus d'essieux.
Enfin, il apparait logique que la température du système `T` soit fortement corrélée négativement à la variable temporelle `Time_num` car les données ont été récupérées de l'été 2017 à novembre 2017.

### Etude des liaisons entre variables quantitatives

On constitue le jeu de données finales, se composant des variables quantitatives et qualitatives utiles :
```{r}
# Jeu de donnée final
siwim_final <-cbind(varquali2,varquanti2)

# Transformation en data table
setDT(siwim_final)
```

Intéressons nous aux variables quantitatives et analysons graphiquement leur liaison avec la variable qualitative `Anomalie`:

```{r}
# Température / Ano
ggplot(siwim_final, aes(Anomalie, y=T, group=Anomalie)) + 
geom_boxplot(aes(fill=Anomalie))+
ggtitle("Profil de la temperature en fonction du déclenchement d'anomalie")

# Nb d'essieux / Ano
ggplot(siwim_final, aes(Anomalie, y=N, group=Anomalie)) + 
geom_boxplot(aes(fill=Anomalie))+
ggtitle("Profil du nombre d'essieux en fonction du déclenchement d'anomalie")

# Vitesse / Ano
ggplot(siwim_final, aes(Anomalie, y=Vitesse, group=Anomalie)) + 
geom_boxplot(aes(fill=Anomalie))+
ggtitle("Profil de la vitesse en fonction du déclenchement d'anomalie")

# Masse / Ano
ggplot(siwim_final, aes(Anomalie, y=MGV, group=Anomalie)) + 
geom_boxplot(aes(fill=Anomalie))+
ggtitle("Profil de la masse en fonction du déclenchement d'anomalie")

# Distance totale entre les essieux / Ano
ggplot(siwim_final, aes(Anomalie, y=total_axle_dist, group=Anomalie)) + 
geom_boxplot(aes(fill=Anomalie))+
ggtitle("Profil de la distance totale entre essieux en fonction du déclenchement d'anomalie")


```
 Il est difficile de tirer des conclusions à travers ces graphiques.

Nous envisageons de réaliser des analyses multidimentionnelles qui permettront de résumer les informations et les relations entre les variables.

# Analyse Factorielles

Les analyses factorielles permettent de résumer l'information contenues dans nos données.

L'analyse en composante principale permet de résumer l'information conjointe entre des données quantitatives, en captant les relations linéaires entre les variables.

L'analyse des correspondances multiples, permet quant à elle de résumer l'information entre variables qualitatives.

Nous décidons ici d'utiliser le package `FactoMineR` et d'utiliser la méthode `AFDM (Analyse Factorielle des Donnée Mixtes)`, en anglais FAMD (Factor Analysis for Mixed Data), dont l'intéret est de construire un nouveau système de représentation (facteurs, axes factorielles : combinaisons linéaires des variables quantitatives et des indicatrices des variables qualitatives) qui permet de synthétiser l'information.

Nous souhaitons avoir les réponses aux questions suivantes :

* Quels sont les camions qui se ressemblent (proximité entre les individus) ?
* Sur quelles caractéristiques sont fondées les ressemblances / dissemblances ?
* Quelles sont les relations entre les variables ?
* Quelles sont les relations entres les modalités et les variables quantitatives ?

## Analyse Factorielle des Donnees Mixes (AFDM)

```{r}
# Calcul de l'AFDM
res_FAMD <-FAMD(siwim_final[,-c(1:3)], graph = FALSE,ncp = 5)
```

Etudions la variance (inertie) expliquée par les axes de l'analyse factorielle :

```{r}
eig_val <- get_eigenvalue(res_FAMD)
head(eig_val)
```

Le premier plan factoriel explique 13% de l'inertie totale. Cela signifie que 13% de l'information du nuage est expliquée par cet axe. **Cela est relativement faible**.

Les 5 premiers axes exliquent quant à eux seulement 22 % de l'inertie totale, ce qui est insuffisant pour une réduction de dimenssionnalité à utiliser en entrée d'un traitement ultérieur.

Le but recherché est de trouver une représentation synthétique des donnée, afin de notamment caractériser des groupes de camions par clustering s'appuyant sur cette représentation.

Les variables qualitatives sont essentiellement des variables de contexte (heure, jour, mois de passage, ainsi que la variable `Anomalie` déclenchée par le système de pesage.)
Les variables quantitatives sont essentiellement des descripteurs des camions.

Nous proposons donc d'appliquer une Analyse en Composantes Principales sur les données quantitatives avec les **variables qualitatives en illustration**. Ces variables qualitatives ne participeront pas à la construction des axes, mais en faciliteront leur description.


## Analyse en Composantes Principales (ACP)

```{r}
# Preparation du jeu de donnee
don_PCA <- cbind.data.frame(varquanti2,varquali2[,c("Mois_annee","Jour_semaine","Heure","Lane","Anomalie")])
```

L'ACP normée (sur données centrées-réduites) est calculée en précisant les variables qualitatives en supplémentaires :

```{r}
# Calcul de l'ACP avec variables qualitatives supplementaires
res_PCA <-PCA(don_PCA, scale.unit = TRUE, graph = FALSE,ncp = Inf, quali.sup = 8:12)
```


### Variance / Inertie Expliquee

Etudions la variance (inertie) expliquée par les axes de l'analyse factorielle :

```{r}
eig_val <- get_eigenvalue(res_PCA)
head(eig_val)
```

Les 7 premières composantes principales capturent 100%  de l'inertie (variabilité) du nuage de point initial
les 4 premières 89% et les 5 premières 94%. 
Nous proposerons plus loin de conserver un sous-ensemble d'axes capturant l'essentiel de la variabilité et réduisant le nuage de points initial en évitant d'utiliser des axes supplémentaires qui seront assimilés à du bruit.
Nous rappelons que l'ACP "capture" ou met en évidence les relations linéaires entre les variables. Nous sommes conscients que les relations non linéaires entre les variables ne seront ici pas mises en évidence.

Une méthode couramment utilisée est celle consistant à afficher le graphique du coude (scree plot) :

```{r}
fviz_eig(res_PCA, addlabels = TRUE, ylim = c(0, 50))
```

Le nombre d’axes est déterminé par le point, au-delà duquel les valeurs propres restantes sont toutes relativement petites et de tailles comparables (Jollife 2002, Peres-Neto, Jackson, and Somers (2005)).

Nous proposerons de conserver par la suite les 4 premières composantes principales qui représentent 89% de la variation.

Le premier plan factoriel, présente l'intérêt d'être facilement interprétable (dimension 2) et de résumer 61 % de l'information. Les représentations graphiques qui suivront concerneront ce plan.


### Graphiques des individus

Affichons le nuage des individus (camions) dans le premier plan factoriel, ainsi que les modalités des variables qualitatives supplémentaires :   

```{r}
# Graphique des individus
p <- fviz_pca_ind(res_PCA)
fviz_add(p,res_PCA$quali.sup$coord,color = "red")
```

Il y a trop d'individus affichés, et il est donc impossible de débusquer des groupes de camions à l'oeil nu.
Cette représentation permet par contre de constater la présence d'individus se détachant par leur valeur. Ainsi, l'individu **95521** a une coordonnée très forte sur l'axe 1 et a donc des valeurs fortes par rapport aux variables qui seront fortement corrélées à cet axe.
Ce type d'individu peut être un outlier ou constituer un parangon, c'est à dire un représentant fort de la classe à laquelle il appartient.

Nous allons analyser visuellement la qualité de représentation des individus (cos2) :

Un point est dit bien représenté sur  un axe  ou un plan factoriel si il est proche de sa projection sur l’axe ou le plan. S’il est éloigné, on dit qu’il est mal représenté.  L'Indicateur est l'angle formé entre le point et sa projection sur l’axe (cos proche de 1 correspond à un individus bien representé).

Représentons les 100 individus ayant le plus contribué à la construction des deux axes du plan factoriel principal, en colorant suivant la qualité de la représentation du point :

```{r}
# Graphique des 100 individus les plus contributeurs suivant leur qualite de representation
p<- fviz_pca_ind(res_PCA, col.ind = "cos2", select.ind = list(contrib= 100)) + 
               labs(title ="100 individus les plus contributeurs à la construction du premier plan factoriel")
fviz_add(p,res_PCA$quali.sup$coord,color = "red")
```

Nous remarquons à l'aide de cette représentation visuelle, les points bien représentés (en bleu clair) et ceux dont la qualité de la représentation est moindre (bleu foncé), parmi les individus contribuant le plus à la construction des axes.

Nous proposons une représentation visuelle, des 100 individus contribuant le plus à la construction du premier plan principal, en les colorant suivant si une anomalie a été déclenchée ou non durant leur passage :


```{r}
# Graphique des 100 individus les plus contributeurs avec coloration suivant la modalité de la variable Anomalie
p <- fviz_pca_ind(res_PCA, select.ind = list(contrib= 100), habillage = siwim_final$Anomalie) +
  labs(title ="100 individus les plus contributeurs à la construction du premier plan factoriel")
fviz_add(p,res_PCA$quali.sup$coord,color = "red")
```

Le résultat visuel est étonnant : alors que seul 1 camion sur trois fait l'objet d'une anomalie déclenchée par le système de pesage, nous voyons clairement que la majorité des contributeurs aux axes sont des camions ayant déclenché une Anomalie.
Ceci parait potentiellement cohérent avec les éventuelles valeurs fortes que prendraient ces camions par rapport à certaines valeurs physiques (surpoids).


### Graphique des variables

Nous allons visualiser les variables et formuler des conclusions concernant leur corrélation. Nous étudierons la qualité de leur représentation et leur contribution aux composantes principales.

```{r}
# Cercle des correlations coloré en fonction de la qualité de représentation 
fviz_pca_var(res_PCA, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Évite le chevauchement de texte
             ) + labs(title ="Cercle des corrélations - PCA")
```


Ce graphique montre les relations entre les variables qui sont regroupées quand elles sont corrélées. 

Ici `N`(nombre d'essieux), `MGV`(masse du camion),`total_axle_dist` (distance totale entre les essieux les plus distants) sont fortement corrélés à la fois entre elles et à l'axe 1. Ces trois variables sont corrélées négativement à `Vitesse`.

**Le premier axe oppose les camions les plus volumineux (car nombre d'essieux importants, masse importante, et longueur importante) au camion les plus petits, les moins lourds et qui sont les plus rapides.**

**Le deuxième axe montre que la température `T` est corrélée négativement à la variable `Time_Num` qui est la variable de temps (continue).**
`Time_num` est la variable numérique du temps : ici on montre que plus `Time_num` est importante, plus la température est basse.
Ce qui est logique car la prise de mesure s'est déroulée entre depuis de l'Eté à l'hiver.

### Contributions des variables aux axes principaux

```{r}
# Contribution des variables
res_PCA$var$contrib
```

Plus la valeur de la contribution est importante, plus la variable contribue à la composante principale en question.
Ainsi `N`, `total_axle_dist`, `MGV` contribuent le plus fortement à l'axe 1.
`T` et `Time_num` expliquent à elle deux la variabilité de l'axe 2.

```{r}
# Contributions des variables à composante 1
fviz_contrib(res_PCA, choice = "var", axes = 1)
# Contributions des variables à composante 2
fviz_contrib(res_PCA, choice = "var", axes = 2)
```

```{r}
# Qualite de representation des variables
res_PCA$var$cos2
```

la qualité de représentation (le cos2) est très bonne pour `N`et `total_axle_dist` et `MGV`. 
`Vitesse` n'a pas une représentation excellente
Sur l'axe 2, `T` et `Time_Num` sont très bien représentées.


### Description des dimensions

Nous avons decrit précédemment les axes constituant les deux dimensions du plan principal.

La fonction suivante est utilisée pour identifier les variables les plus significativement associées à une composante principale. 

```{r}
dimdesc(res_PCA, axes = c(1,2), proba = 0.05)
```

La fonction de description `dimdesc` permet de mettre en évidence la relation des variables qualitatives supplémentaires (ainsi que leur modalité) avec les axes factoriels.
Nous avons vu précédement dans les affichage graphiques, que le nuage des modalités des variables qualitatives se "concentrait" au centre du plan. Les variables qualitatives sont certes liées aux axes, mais possèdent des coordonnées ne prenant pas de valeurs significativement hautes ou basses, ce qui empêche de tirer des conclusions.

Nous observons à titre d'exemple que la modalité `N` de la variable `Anomalie` a une coordonnée positive sur l'axe 1 (inversement pour la modalité `Y`) ce qui pourrait s'interpréter de la façon suivante : "les camions prenant des valeurs positives sur l'axe 1 ont tendance à ne pas déclencher d'anomalie". Nous rappelons que les camions prenant des valeur positives sur cet axe semblent être les plus volumineux.  

Concernant l'axe 2, il est beaucoup plus net que la variable `Mois_annee` soit bien représentée. Ses modalités ont des coordonnées plus fortes en valeur absolue, discriminant le groupe de modalité `octobre, novembre` avec celui `Juillet, Aout`. Rappelons que cet axe discrimine les camions enregistrés lors d'une prise de température forte en opposition à ceux enregistrés lors d'une prise de température faible du système.


# Clustering (apprentissage non supervisé)

Nous avons vu précédemment que suite à l'ACP, les 4 premières composantes principales expliquaient 89 % de la variabilité.
Nous réduisons donc notre nuage de point en effectuant une nouvelle ACP en ne conservant que les 4 premières variables.

Chaque algorithme de clustering sera exécuté sur ce nouvel ensemble.

```{r}
# On réalise un prétraitement par ACP normée en gardant 4 dimensions
res_PCA2 <- PCA(varquanti2, scale.unit = TRUE, graph = FALSE,ncp = 4)

# On stocke les 4 premieres composantes principales dans un data frame
don_PCA_clusters <- data.frame(res_PCA2$ind$coord)
```

Chaque méthode testée produira ses clusters, qui seront stockés dans le data frame contenant les coordonnées des axes factoriels, afin de faciliter les comparaisons et représentations ultérieures. 


## Méthode hiérarchique : 

Les méthodes hiérarchiques présentent l'intérêt de proposer un nombre optimal de cluster, dont le découpage est réalisé en optimisant un critère. 

###  kmeans + CAH sur composantes principales

Notre jeu de donnée contient plusieurs centaines de milliers d'individus. Nous allons donc être exposés à des problèmes calculatoires et de mémoire.

Afin de contourner cette difficulté, nous allons réaliser en amont un partitionnement à l'aide des Kmeans. Nous fixons un nombre de partitions grand, avec pour objectif d'obtenir pour chacune une faible inertie intra-classe (homogéneité).

On met ensuite en oeuvre une classification ascendante hiérarchique (CAH) sur ces groupes d'individus issus de l'étape précédente et on obtient une hiérarchie qui est approximativement la haut de la hiérarchie que l'on obtiendrait en classifiant les individus directement.


```{r}
# Kmeans sur un nombre grand nombre de clusters
set.seed(123)
res_kmeans_grand <- kmeans(don_PCA_clusters[,c("Dim.1","Dim.2","Dim.3","Dim.4")],centers=1000,iter=100)
```

On effectue ensuite une CAH sur les centres des classes :

```{r}
# Calcul de la matrice de distance (euclidienne)
dist <- dist(res_kmeans_grand$centers,method="euclidean")

# Classification Ascendante Hierarchique (methode de Ward)
cah <- fastcluster::hclust(dist,method="ward.D")

# Affichage dendrogramme
plot(as.dendrogram(cah),main="Ward")

```

3 ou 4 groupes semblent se détacher.


```{r}
# Recherche du nombre de classe
plot(sort(cah$height,decreasing=TRUE),xlim=c(0,35),type="h",ylab="Hauteur",main="Ward")
lines(sort(cah$height,decreasing=TRUE),xlim=c(0,35))
abline(v=3, lty=2, col='gray60')

```

Un niveau de coupure à 3 ou 4 classes semble être envisageable.

Nous décidons de couper à 3 classes:

```{r}
# On décide du niveau de coupure
classes_centres <- cutree(cah,k=3)

# Nous rajoutons la variable de classe au jeu de données contenant les axes factoriels
don_PCA_clusters$clusters_cah_mixte <- as.factor(classes_centres[res_kmeans_grand$cluster])
```

Représentons sur le premier axe factoriels, les individus colorés en fonction de leur groupe déterminés par la CAH mixte.

```{r}
# Affichage sur le premier plan principal des individus en fonction de leur groupes
ggplot(don_PCA_clusters, aes(x=Dim.1, y=Dim.2, color=clusters_cah_mixte)) + geom_point() +
    labs(title ="Représentation des camions sur le premier plan factoriel")
```

```{r}
# Description des catégories
```


## Partitionnement : K-means sur composantes principales

L'algorithme des kmeans nécessite de fixer à priori le nombre de classes, et l'initialisation au hazard peut donner des résultats assez variables.
Nous faisons varier le nombre de classes et observer le résultat, en optimisant le rapport d'inertie

```{r}
# kmeans sur 3 groupes
set.seed(123)
res_kmeans <- kmeans(don_PCA_clusters[,c("Dim.1","Dim.2","Dim.3","Dim.4")],centers=3,iter=500)

# Nous rajoutons la variable de classe au jeu de données contenant les axes factoriels
don_PCA_clusters$clusters_kmeans <- as.factor(res_kmeans$cluster)
```

```{r}
# Affichage sur le premier plan principal des individus en fonction de leur groupes
ggplot(don_PCA_clusters, aes(x=Dim.1, y=Dim.2, color=clusters_kmeans)) + geom_point() +
    labs(title ="Représentation des camions sur le premier plan factoriel")
```


### Estimation du nombre de clusters

```{r}
# fviz_cluster(res_kmeans, data = res_PCA2$ind$coord,
#              palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"), 
#              ellipse.type = "euclid", # Concentration ellipse
#              star.plot = TRUE, # Add segments from centroids to items
#              repel = TRUE, # Avoid label overplotting (slow)
#              ggtheme = theme_minimal()
#              )
```

 
## Partitionnement k - medoides : CLARA

Il s'agit d'un extension aux méthodes k-medoides pour traiter de grands jeux de données (plusieursmilliers d'observations). Elle est donc adaptée à notre contexte :

```{r}
# On applique la méthode CLARA sur 3 groupes
set.seed(123)
res_clara <- clara(don_PCA_clusters[,c("Dim.1","Dim.2","Dim.3","Dim.4")],k = 3)

# Nous rajoutons la variable de classe au jeu de données contenant les axes factoriels
don_PCA_clusters$clusters_clara <- as.factor(res_clara$clustering)

```

```{r}
# Affichage sur le premier plan principal des individus en fonction de leur groupes
ggplot(don_PCA_clusters, aes(x=Dim.1, y=Dim.2, color=clusters_clara)) + geom_point() +
    labs(title ="Représentation des camions sur le premier plan factoriel")
```


## Partitionnement basé sur densité : DBscan / Optics

```{r}

```

##  Méthodes neuronales : cartes auto-adaptatives de Kohonen (SOM)

```{r}

```

##  Interprétation des classes

Nous interpretons les classes construites dans chaque méthode. L'idée est de dégager une interprétation commune, favorisant l'utilité métier. 



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
