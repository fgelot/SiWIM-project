---
title: "Découverte du jeu de données du projet SIWIM"
output: 
  html_document:
    df_print: paged
---

```{r "setup", include=FALSE}
# Configuration locale du chemin du projet SIWIM :
knitr::opts_knit$set(root.dir = normalizePath("Z:/Data Science/R/SiWIM-project"))
```

# Feature engineering

Nous allons dans cette section partir des données brutes afin de les retravailler en recodant certaines variables

```{r, message=FALSE,warning=FALSE}
# chargement des librairies 

library(data.table)
library(stringr) # manipulation de chaine de caracteres
library(missMDA) # imputation des données manquantes
library(questionr) # calcul Vcramer et des fréquences
library(ggplot2)

```

```{r}
# Chargement des données brutes, récupérées par scraping et reformatées
siwim_data <- fread("2_Data/2_Retraitees/SiWIM_data_formated.csv")

```

Nous recodons / renommons certaines variables qualitatives :

```{r}
# Suppression de variables inutiles
siwim_data[, c("Stage_trace", "Offset", "Impact_factor") := NULL]

# Conversion en factor de la variable Site_ID
siwim_data[, Site_ID := as.factor(Site_ID)]

# Conversion en factor de la variable Warning_flags
siwim_data[, Warning_flags := as.factor(Warning_flags)]

# Recodification de la variable lane (0 = droite, 1 = gauche)
siwim_data[, Lane := factor(siwim_data$Lane, labels = c("droite", "gauche"))]

# Conversion en factor de la variable Subclass_ID
siwim_data[, Subclass_ID := factor(siwim_data$Subclass_ID)]

# Conversion en factor de la variable Axle_groups
siwim_data[, Axle_groups := factor(siwim_data$Axle_groups)]

# Renommage et conversion en factor de la variable N (nombre d'axes)
siwim_data[, Nb_axles := factor(siwim_data$N)]
```

De nouvelles variables de date sont créées à partir de la variable `timestamp`:

```{r}
# Creation de variables depuis timestamp au format POSIXct :
siwim_data[, Date    := as.POSIXct(substr(siwim_data$Timestamp,1,10), format = '%Y-%m-%d')]
siwim_data[, Horaire := substr(siwim_data$Timestamp,12,19)]
siwim_data[, Timestamp := as.POSIXct(substr(siwim_data$Timestamp,1,19), format = '%Y-%m-%d %H:%M:%S')]

# Création d'une variable temporelle quantitative depuis le 1er Janvier 2017

siwim_data[, Time_num := as.numeric((siwim_data$Timestamp - as.POSIXct("2017-01-01 00:00:00", format = '%Y-%m-%d %H:%M:%S'))/360)]

# Creation de variables temporelles de type factor
siwim_data[, Annee := as.factor(strftime(siwim_data$Date, format = "%Y"))]
siwim_data[, Mois_num := as.factor(strftime(siwim_data$Date, format = "%m"))]
siwim_data[, Mois_annee := as.factor(strftime(siwim_data$Date, format = "%B"))]
siwim_data[, Jour_num := as.factor(strftime(siwim_data$Date, format = "%d"))]
siwim_data[, Jour_semaine := as.factor(strftime(siwim_data$Date, format = "%A"))]
siwim_data[, Heure := as.factor(str_sub(Horaire, 1, 2))]
```

Creation de la variable qualitative `Anomalie` :

```{r}
siwim_data[,Anomalie := "N"][Warning_flags != "00000000",Anomalie := "Y"]

# Transformation en factor
siwim_data[, Anomalie := factor(siwim_data$Anomalie)]
```

Plusieurs variables ont des unités anglo-saxonnes, nous les recalculons dans des unités européennes :

```{r}

# Passage de la vitesse en km/h
siwim_data[, Vitesse := siwim_data$v * (36/10)]

# Passage du poids en tonnes
siwim_data[, MGV := siwim_data$WGV / 9.81]

# Passage du poids de chaque essieu en tonnes
maxN <- 16
axles_load <- paste("W", 1:maxN, sep = "")
axles_mass <- paste("M", 1:maxN, sep = "")
axles_load
siwim_data[, (axles_mass) := lapply(axles_load, function(x){get(x)/9.81})]
```

Certaines variables désormais inutiles sont retirées :
```{r}
# Suppression de la variable index V1 avant écriture des données dans le .csv
siwim_data[, V1 := NULL]

# Suppression des variables d'origine codées dans des unités anglo-saxonnes
siwim_data [, c("v","WGV", "W1","W2","W3","W4","W5","W6","W7","W8","W9","W10",
         "W11","W12","W13","W14","W15","W16") := NULL]
```

# Résumés et valeur manquantes

Le jeu de données contient 54 variables et environ 184 000 lignes :

```{r}
dim(siwim_data)
```

Chaque ligne représente les valeurs des variables pour un camion capturé par le système de pesage par poids du Pont de Normandie.

Il est important de rappeler que le système comporte sa propre fiabilité et est possiblement amené à capturer du bruit ou à dysfonctionner.

Nous notons ici la présence de nombreuses valeur manquantes ou de valeur aberrantes lorsque nous analysons par exemple les minimum ou les maximum de certaines variables.


```{r}
summary(siwim_data)
```

Nous allons créer deux dataframe :

- `varquali` contiendra les variables qualitatives
- `varquanti` contiendra les variables quantitatives

```{r}
varquanti <- siwim_data[, lapply(siwim_data, is.numeric) == TRUE, with = FALSE]
varquali <- siwim_data[,lapply(siwim_data,is.numeric) == FALSE, with = FALSE]
```

Regardons à présent le résumé concernant les variables quantitatives :

```{r}
summary(varquanti)
```

Les variables `Ai` représentant la distance entre chaque essieu comportent de nombreuses valeur manquantes. Le nombre d'essieu constaté dans le jeu données maximum etant de 16 (valeur non réaliste), le tableau comporte ainsi 16 valeur de `Ai`.

Même raisonnement pour la masse sur chaque essieu où 16 variables `Mi` sont présentes dans le jeu de données et comportent des valeurs manquantes.

Le nombre de valeurs manquantes n'étant pas négligeable, il faudra les traiter comme nous le verrons ci-après.

```{r}
summary(varquali)
```
Pour les variables qualitatives, seule la variable `Axles_groups` comportent des valeurs manquantes (9)

En résumé : la qualité du jeu de donnée est bonne du point de vue des valeurs manquantes.

# Analyse unidimensionnelle des variables qualitatives

Nous analysons les fréquences des modalités de chaque variable qualitative.

```{r}
# Mois de circulation
freq(varquali[,.(Mois_annee)], cum = TRUE, total = TRUE, sort = "dec") 
```

Nous remarquons que les données ici représentées le sont sur un espace de temps limité. 
On note un léger pic de circulation l'Eté.

```{r}
# jour de circulation
freq(varquali[,.(Jour_semaine)], cum = TRUE, total = TRUE, sort = "dec")
```
Les jours de la semaines sont les plus circulés par les poids lourds.
Les moins circulés sont le week-end, ce qui est assez net.

Pour rappel En France, à l’exclusion des véhicules spécialisés et des matériels et engins agricoles, les camions n’ont pas le droit de circuler du samedi 22 heures au dimanche 22 heures. Cette interdiction générale s’applique également les veilles de jours fériés à partir de 22 heures jusqu’à 22 heures le lendemain.


```{r}
# heure de circulation
freq(varquali[,.(Heure)], cum = TRUE, total = TRUE, sort = "dec")
```

Les camions semblent moins circuler de 20h à 5h (donc la nuit) qu'en journée. En effet, environ 90 % des passages ont lieu entre 6h et 19h.


```{r}
# voie 
freq(varquali[,.(Lane)], cum = TRUE, total = TRUE, sort = "dec") 
```

Lors de la capture des données 91% des camions ont roulé à droite. Les 9% ayant roulé à gauche réalisaient-ils un dépassement ?


```{r}
freq(varquali[,.(Anomalie)], cum = TRUE, total = TRUE, sort = "dec") 
```

29 % des passages ont été taggé en anomalie. 

Analysons le détail, en excluant la modalité `00000000` signifiant qu'il n'y a pas d'anomalie :

```{r}
freq(varquali[,.(Warning_flags)], exclude = c("00000000"), cum = TRUE, total = TRUE, sort = "dec") 
```

Les anomalies les plus fréquentes sont donc :

- `00008000` : vehicle reconstructed
- `00800000` : vehicle overloaded
- `00000001` : multiple truck presence
- `00000080` : negative axle loads or WGV
- `00000081` : ?
- `00000200` : vehicle reclassified


```{r}
# Subclass_ID : classification réalisée par le système de pesage
freq(varquali[,.(Subclass_ID)], cum = TRUE, total = TRUE, sort = "dec")
```
Les deux classifications les plus fréquentes réalisées par le systèmes sont 113 et 61 (50% à elles deux)


```{r}
# Groupe d'essieux (constatés)
freq(varquali[,.(Axle_groups)], cum = TRUE, total = TRUE, sort = "dec")
```
Seul 113 ressort comme sur la classification réalisée par le système.

[Idée] : il pourrait etre intéressant de considérer comme un label (Y) le groupe d'essieux, et de réaliser une classification en la comparant à celle réalisée pour le système (Subclass Id) 



```{r}
# Nombre d'essieux
freq(varquali[,.(Nb_axles)], cum = TRUE, total = TRUE, sort = "dec")
```

95 %  des camions ont 2,3, 4 ou 5 essieux.
Nous observons des valeurs allant jusqu' à 16 essieux.
Nous considérons comme aberrant le fait qu'un camion ait plus de 8 essieux.


# Analyse unidimensionnelle des variables quantitatives

Nous allons étudier la distribution et la distribution des variables quantitatives à l'aide de boites à moustache (boxplot)



La variable quantitative `N` représente le nombre d'essieux, à l'instar de `Nb_Axles` qui est qualitative

```{r}
# Nombre d'essieux
ggplot(varquanti,aes("", y = N)) + geom_boxplot()

```
la médiane du nombre d'essieux est 5. On observe des valeurs aberrantes car on considère qu'un nombre d'essieux supérieur à 8 est anormal.

```{r}
# Nombre de camions ayant plus de 8 essieux
siwim_data[N > 8, .N]
```


```{r}
# Distance totale entre les essieux les plus éloignés
ggplot(varquanti,aes("", y = total_axle_dist)) + geom_boxplot()

```

`Total_axle_dist` exprime la distance total entre les essieux les plus éloignés du camion. Elle donne une approximation de la taille (une taille minimale) du camion.

Nous constatons que de nombreuses valeur sont aberrantes car cette distance va jusqu'à 80 mètres :

```{r}
# Nombre de camions avec une distance totale entre essieux supérieure à 20 m
siwim_data[total_axle_dist > 20, .N]
```

En France, la longueur maximale autorisée est autour de 18.50 mètres, nous considérons donc qu'au-delà de 20 mètres la valeur est aberrante. 




```{r}
# Temperature utilisée par la compensation
ggplot(varquanti,aes("", y = T)) + geom_boxplot()

```

```{r}
# Enregistrement de température inférieur à -20 degrés
siwim_data[T < -20, .N]
```

Nous constatons des valeurs clairement aberrantes, toutes situées à -273 degrés.


```{r}
varquanti[T == -273,.N]
```

Ces valeurs sont au nombre de 2014. Il faudra donc les traiter.
L'observation des indices semblent montrer une continuité dans la captation de cette valeur aberrante.

```{r}
# Vitesse
ggplot(varquanti,aes("", y = Vitesse)) + geom_boxplot()
```

La vitesse mediane est autour de 70km/h.
Plusieurs vitesses apparaissent excessives (peut on rouler a plus de 130 km/h avec un camion ?). 

```{r}
# Nombre de camions avec une vitesse supérieure à 130 km/h
siwim_data[Vitesse > 130, .N]
```
Les derniers tracteurs de Volvo le peuvent. Mais nous pensons plutôt que ceux-ci ne fréquentent pas le pont de Normandie où la vitesse est de plus limitée à 90 km/h et que les camions chargés ont du mal à monter la pente. Nous devrons donc corriger ces valeurs aberrantes.


```{r}
# Masse du camion
ggplot(varquanti,aes("", y = MGV)) + geom_boxplot()
```

La Mediane du poids a 19 tonnes.
Plusieurs valeurs semblent aberrantes (des camions de plus cent tonnes ou des camions avec un poids de 0 tonnes). 

```{r}
# Camion avec un poids global supérieur à 70 tonnes
siwim_data[MGV > 70, .N]

```

La limite légale étant à 44 tonnes et des poids lourds peuvent être surchargés, mais à partir de 70 tonnes il est sûr que les essieux ne tiennent pas la charge. 
Nous considérerons cette limite pour traiter les valeurs aberrantes. 

De plus, il existent un nombre important de camions dont le poids est égal à 0 :

```{r}
# Nombre de camions avec un poids égal à 0
siwim_data[MGV == 0, .N]
```

Ces valeurs manquantes devront être traitées.


# Traitement des valeurs manquantes et aberrantes

Deux types de valeurs doivent être retraitées :

- les valeurs **manquantes**, qui doivent soit être estimées, soit éliminées par suppression de l'enregistrement associé
- les valeurs **aberrantes**, qui doivent soit être corrigées, soit éliminées par suppression de l'enregistrement associé

Nous allons explorer ces deux approches, en construisant deux jeux de données. Le premier avec des valeurs estimées, le deuxième avec des valeurs supprimées.

On travaille sur le tableau simplifié des variables quantitatives.  

**Idée générale** : attribuer aux données aberrantes (dont nous sommes surs qu'elles soient fausses) un valeur "NA" puis reconstituer leur valeur grasse aux techniques d'imputation du package `"missMDA"`.

Les seuils sont fixés à partir de la connaissance métier.

```{r}
# On considere qu'une valeur supérieure à 8 essieux est aberrante
siwim_data[siwim_data$N > 8, N := NA]
siwim_data[is.na(siwim_data$N), Nb_axles := NA]

```

```{r}
# On considere comme valeur anormale une distance totale entre les axes > à 20 m
siwim_data[total_axle_dist > 20, total_axle_dist := NA]

```

```{r}
# On considere comme valeur anormale les températures négatives < à -10°C
siwim_data[T < -20, T := NA]
```

```{r}
# On considere comme valeur anormale la vitesse d'un camion > à 130 km/h
siwim_data[Vitesse > 130, Vitesse := NA]
```

```{r}
# On considere comme valeur anormale la masse d'un camion > à 70 T ou égale à 0
siwim_data[MGV > 70 | MGV == 0, MGV := NA]
```


On supprime des variables liées à un trop grand nombre d'axes :

```{r}
siwim_data [, c("A8", "A9","A10","A11","A12","A13","A14","A15","M9","M10",
                "M11","M12","M13","M14","M15","M16") := NULL]
```

On prépare le jeu de donnees `siwim_data_imput` contenant seulement les variables utiles pour l'imputation :

```{r}
siwim_data_imput <- siwim_data[, c( "Lane", "N", "Nb_axles", "Anomalie", "total_axle_dist", "T", 
   "Reduced_chi_squared", "Time_num", "Vitesse", "MGV")]
```

L'imputation est réalisée par analyse factorielle des données multiples (FAMD) du package `Factominer`.
Nous retenons l'information apportée par 7 axes factoriels :

```{r}
siwim_data_inputted <- imputeFAMD(siwim_data_imput, ncp = 7, method = "Regularized")
```

Voici le résumé des données après imputation :
```{r}
summary(siwim_data_inputted$completeObs)
```

```{r}
# Transformation en data frame :
siwim_data_inputted <- as.data.frame(siwim_data_inputted$completeObs)
```

On concatène les variables imputées avec les colonnes initiales
```{r}
siwim_data_inputted_final <- cbind(siwim_data[, -c( "Lane","N", "Nb_axles", "Anomalie", "total_axle_dist", "T", "Reduced_chi_squared", "Time_num", "Vitesse", "MGV")],siwim_data_inputted)
```

Voici le résumé du jeu de données final après imputation, en comparaison de celui obtenu initialement :

```{r}
summary(siwim_data[,.( Lane,N, Nb_axles, Anomalie, total_axle_dist, T, Reduced_chi_squared, Time_num, Vitesse, MGV)])
summary(siwim_data_inputted_final[,.( Lane,N, Nb_axles, Anomalie, total_axle_dist, T, Reduced_chi_squared, Time_num, Vitesse, MGV)])
```

L'imputation semble donner de bons résultats. Etant basée sur une méthode d'estimation, les valeurs imputées peuvent de nouveaux franchir les limites fixées.
Nous pouvons soit les supprimer, soit imputer aux valeurs limites de manière à conserver la donnée et donc le plus d'information possible.

```{r}
# Fixation aux valeurs limites pour les imputations qui auraient franchies les limites théoriques
siwim_data_inputted_final[N > 8, N := 8]
siwim_data_inputted_final[total_axle_dist > 20, total_axle_dist := 20]
siwim_data_inputted_final[T < -20, T := -10]
siwim_data_inputted_final[Vitesse > 130, Vitesse := 130]
siwim_data_inputted_final[MGV < 0, MGV := 0.5]
siwim_data_inputted_final[MGV > 70, MGV := 70]
```


La deuxième approche consiste à éliminer les individus ayant des valeurs manquantes et / ou aberrantes.

```{r}
## Suppression des individus comportant des donnees manquantes
siwim_data_missing_del <- siwim_data[!is.na(siwim_data$N)
                                            & !is.na(siwim_data$total_axle_dist) 
                                            & !is.na(siwim_data$T)
                                            & !is.na(siwim_data$Vitesse)
                                            & !is.na(siwim_data$MGV)]
```

Résumé des données sans ces valeurs aberrantes :

```{r}
summary(siwim_data_missing_del[,.( Lane,N, Nb_axles, Anomalie, total_axle_dist, T, Reduced_chi_squared, Time_num, Vitesse, MGV)])
```

Nous constatons que les deux méthodes semblent aboutir à des résultats similaires : les résumés montrent que les valeur prises par les indicateurs de dispersion et de position restent semblables.

Nous stockons à présent nos trois jeux de données pour les prochaines analyses :

```{r}
write.csv(siwim_data, file = "2_Data/2_Retraitees/SiWIM_data_prepared.csv")

write.csv(siwim_data_inputted_final, file = "2_Data/2_Retraitees/SiWIM_data_after_input.csv")

write.csv(siwim_data_missing_del, file = "2_Data/2_Retraitees/SiWIM_data_missing_deleted.csv")
```


